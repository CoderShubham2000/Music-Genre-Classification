{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_speech_features import mfcc # Used to classify these speech features (library that supports the speech features) and the most common is Mel Frequency Cepstral Coefficients -> Used to extract the low frequency and time related features within the wav files that we can use to train the model\n",
    "import scipy.io.wavfile as wav # Used to extract and read the .wav files\n",
    "import numpy as np\n",
    "\n",
    "from tempfile import TemporaryFile # Used to create temporary files and directories\n",
    "\n",
    "import os # Portable way of using Operating System Dependent functionalities\n",
    "import pickle # Pickle model implements binary protocols for serializing and de-serializing a python obejct structure\n",
    "import random\n",
    "import operator\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the distance between feature vectors and find neighbors (Calculates the distance between all the points in the dataset)\n",
    "def getNeighbors(trainingSet, instance, k): #instance is the input that we get and k is the hyperparameter (number of nearest neighbours)\n",
    "    distances = []\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = distance(trainingSet[x], instance, k) + distance(instance, trainingSet[x], k) # To get the distance between two neighbours\n",
    "        distances.append((trainingSet[x][2], dist)) # Appending them to distances list for storing them all\n",
    "\n",
    "    distances.sort(key=operator.itemgetter(1)) # Sorting the data (1st value will be nearest neighbour, 2nd one will be next nearest neighbour)\n",
    "    neighbors = []\n",
    "    for x in range(k): # We are only interested in the K nearest neighbour hence this loop is running upto k\n",
    "        neighbors.append(distances[x][0]) # Appends the same to the new list neighbours[]\n",
    "    \n",
    "    return neighbors # Returning the list back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the class of the instance(Neighbours) (Those having the maximum frequency count)\n",
    "def nearestClass(neighbors):\n",
    "    classVote = {}\n",
    "\n",
    "# We will be having k classes, one for each neighbour\n",
    "\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x]\n",
    "        if response in classVote:\n",
    "            classVote[response] += 1\n",
    "        else:\n",
    "            classVote[response] = 1\n",
    "# The class with the maximum count will be selected and will move up in the sorted arraay\n",
    "\n",
    "    sorter = sorted(classVote.items(), key = operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    return sorter[0][0] # Will be chosen as the identified class for this instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model(getting the accuracy i.e those which were correct)\n",
    "def getAccuracy(testSet, prediction):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    \n",
    "    return (1.0 * correct) / len(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory that holds the wav files\n",
    "directory = \"D:/deep-learning-music-genre-classification/Data/genres_original/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary file where we will collect all the features extracted using mfcc (Mel Frequency Cepstral Coefficients)\n",
    "f = open(\"my.dat\", 'wb')\n",
    "\n",
    "# The .wav files were read and was getting converted into a data file called as my.dat, which captures the features that we need\n",
    "i = 0\n",
    "\n",
    "for folder in os.listdir(directory):\n",
    "    i += 1\n",
    "    if i == 11:\n",
    "        break\n",
    "    for file in os.listdir(directory+folder):  # For each file within a given directory      \n",
    "        try:\n",
    "            # Going inside the folder and trying to identify the rate and the signature\n",
    "            (rate, sig) = wav.read(directory+folder+\"/\"+file)\n",
    "# Using the Mel Frequency Cepstral Coefficients function with the signature and rate to identify the specific features based on which we will be categorising the files\n",
    "            mfcc_feat = mfcc(sig, rate, winlen=0.020, appendEnergy=False)\n",
    "            covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "            mean_matrix = mfcc_feat.mean(0)\n",
    "            feature = (mean_matrix, covariance, i)\n",
    "# For each file we are dumping the features into the my.dat datafile\n",
    "            pickle.dump(feature, f)\n",
    "        except Exception as e:\n",
    "            print('Got an exception: ', e, ' in folder: ', folder, ' filename: ', file)        \n",
    "\n",
    "f.close()\n",
    "# We will have the collection of all the features of all the different files irrespective of the genre in the my.dat data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets respectively\n",
    "\n",
    "dataset = []\n",
    "\n",
    "# As the Data file is now created we will load the Data as this it the data which will be used to train the model\n",
    "\n",
    "def loadDataset(filename, split, trSet, teSet): # Loading th dataset \n",
    "    with open('my.dat', 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                dataset.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                f.close()\n",
    "                break\n",
    "\n",
    "# Splitting it on a random basis into a training set and a testing set, Ratio is passed as a value to the dataset\n",
    "# 66% Training Data and rest 34% Testing Data\n",
    "\n",
    "    for x in range(len(dataset)):\n",
    "        if random.random() < split:\n",
    "            trSet.append(dataset[x])\n",
    "        else:\n",
    "            teSet.append(dataset[x])\n",
    "trainingSet = []\n",
    "testSet = []\n",
    "loadDataset('my.dat', 0.66, trainingSet, testSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the distance between neighbours\n",
    "def distance(instance1 , instance2 , k ):\n",
    "    distance =0 \n",
    "    mm1 = instance1[0] \n",
    "    cm1 = instance1[1]\n",
    "    mm2 = instance2[0]\n",
    "    cm2 = instance2[1]\n",
    "    distance = np.trace(np.dot(np.linalg.inv(cm2), cm1)) \n",
    "    distance+=(np.dot(np.dot((mm2-mm1).transpose() , np.linalg.inv(cm2)) , mm2-mm1 )) \n",
    "    distance+= np.log(np.linalg.det(cm2)) - np.log(np.linalg.det(cm1))\n",
    "    distance-= k\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7017543859649122\n"
     ]
    }
   ],
   "source": [
    "# Making predictions using KNN\n",
    "\n",
    "leng = len(testSet)\n",
    "predictions = []\n",
    "for x in range(leng):\n",
    "    predictions.append(nearestClass(getNeighbors(trainingSet, testSet[x], 5))) # Nearest class function is called which in turn calls the distance function, Nested functions play an important role here\n",
    "\n",
    "accuracy1 = getAccuracy(testSet, predictions)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "defaultdict(<class 'int'>, {1: 'blues', 2: 'classical', 3: 'country', 4: 'disco', 5: 'hiphop', 6: 'jazz', 7: 'metal', 8: 'pop', 9: 'reggae', 10: 'rock'})\n"
     ]
    }
   ],
   "source": [
    "# For each of the different genre based on the folder name a new key value pair is created where the id of the genre will be linked to the genre name\n",
    "\n",
    "from collections import defaultdict \n",
    "results = defaultdict(int) #For Storing the key value pair\n",
    "\n",
    "i=1\n",
    "for folder in os.listdir(directory):\n",
    "    results[i] = folder\n",
    "    i += 1\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the code with external samples\n",
    "# URL: https://uweb.engr.arizona.edu/~429rns/audiofiles/audiofiles.html\n",
    "\n",
    "test_dir = \"D:/deep-learning-music-genre-classification/Test/\"\n",
    "test_file = test_dir + \"test.wav\"\n",
    "# test_file = test_dir + \"test2.wav\"\n",
    "# test_file = test_dir + \"test4.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    }
   ],
   "source": [
    "# Extracting the feature form the test file and use the nearest class prediction function to predict the class\n",
    "(rate, sig) = wav.read(test_file)\n",
    "mfcc_feat = mfcc(sig, rate, winlen=0.020, appendEnergy=False)\n",
    "covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "mean_matrix = mfcc_feat.mean(0)\n",
    "feature = (mean_matrix, covariance, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "classical\n"
     ]
    }
   ],
   "source": [
    "pred = nearestClass(getNeighbors(dataset, feature, 5))\n",
    "print(results[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}